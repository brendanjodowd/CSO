print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
cso_database$Short.Code[i] <- cso_links$Short.Code[i]
}
}
}
library(rvest)
library(purrr)
library(tidyr)
library(dplyr)
library(stringr)
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles
}
#cso_links is the file from the CSV. The short codes here are correct!
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Code <- str_split_fixed(cso_database$Item, " -" , 2)[,1]
cso_database$Short.Code <- ""
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
cso_database$Short.Code[i] <- cso_links$Short.Code[i]
}
}
}
cso_database$Short.Code <- ""
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
cso_database$Short.Code[j] <- cso_links$Short.Code[i]
}
}
}
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
short.code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles <- paste(short.code , " - " , titles)
titles
}
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database <- map(cso_links_vec , extract_links)
sample_link <- "https://www.cso.ie/webserviceclient/datasets.aspx?sp=DB_EY&SPtext=Summary%20Results%20Part%201"
sample_page <- extract_links(sample_link)
sample_page <- unnest(tibble(extract_links(sample_link)))
View(sample_page)
sample_page <- tibble(extract_links(sample_link))
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
# short.code <- link_address %>%
#   str_extract(".*(?=&SPtext)") %>%
#   str_extract("(?<=DB_).*")
# titles <- paste(short.code , " - " , titles)
titles
}
sample_page <- tibble(extract_links(sample_link))
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database <- map(cso_links_vec , extract_links)
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
View(cso_database)
sample_page <- unnest(tibble(extract_links(sample_link)))
sample_page <- tibble(extract_links(sample_link))
sample_page <- extract_links(sample_link)
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("font")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
# short.code <- link_address %>%
#   str_extract(".*(?=&SPtext)") %>%
#   str_extract("(?<=DB_).*")
# titles <- paste(short.code , " - " , titles)
titles
}
sample_page <- extract_links(sample_link)
extract_text <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_text()
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles
}
sample_page <- extract_text(sample_link)
extract_text <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("href") %>% html_text()
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles
}
sample_page <- extract_text(sample_link)
rm(extract_text())
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Short.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Short.Code , titles$Item , sep=" * ")
titles
}
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database <- map(cso_links_vec , extract_links)
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
rm(sample_page)
cso_database$Page.Code <- str_split_fixed(cso_database$Item, " *" , 2)[,1]
cso_database$Code <- str_split_fixed(cso_database$Item, " -" , 2)[,1]
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Page.Code <- str_extract(cso_database$Item, "^.*_ " )
cso_database$Page.Code <- cso_database$Item %>% str_extract(" ")
cso_database$Page.Code <- cso_database$Item %>% str_extract("^.*_ " ) %>% str_replace(" _","")
cso_database$Short.Code <- cso_database$Item %>% str_extract(" _.*- " )
cso_database$Page.Code <- cso_database$Item %>% str_extract("^.{1,10}_ " ) %>% str_replace(" _","")
cso_database$Page.Code <- cso_database$Item %>% str_extract("^.*_ " ) %>% str_replace(" _","")
cso_database$Short.Code <- cso_database$Item %>% str_extract(" _.{1,10}- " )
cso_database$Short.Code <- cso_database$Item %>% str_extract(" _.{1,10}- " ) %>%
str_replace_all("[:punct:]","")
cso_database$New.Item <- str_replace(cso_database$Page.Code , "")
cso_database$New.Item <- str_replace(paste(cso_database$Page.Code) , "")
cso_database$New.Item <- str_replace(paste(cso_database$Page.Code) , "")
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titles
}
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titels$PC <- Page.Code
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titles$PC <- Page.Code
titles
}
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titles$PC <- Page.Code
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles$Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " )
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]") %>% str_replace("[:blank:]")
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
cso_database <- full_join(cso_links , cso_database , by="Short.Code")
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
combined_dataset <- full_join(cso_links , cso_database , by="Short.Code")
library(rvest)
library(purrr)
library(tidyr)
library(dplyr)
library(stringr)
#cso_links is the file from the CSV. The short codes here are correct!
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles$Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
combined_dataset <- full_join(cso_links , cso_database , by="Page.Code")
View(combined_dataset)
cso_database <- full_join(cso_links , cso_database , by="Page.Code")
cso_database_1 <- select(cso_database , -V4)
View(cso_database_1)
rm(cso_database_1)
names(cso_database) <- c("Theme", "Section" , "Subsection", "Page.Code", "Title","Short.Code")
library(rvest)
library(purrr)
library(tidyr)
library(dplyr)
library(stringr)
#cso_links is the file from the CSV. The short codes here are correct!
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles$Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
cso_database <- full_join(cso_links , cso_database , by="Page.Code")
cso_database <- select(cso_database , -V4)
names(cso_database) <- c("Theme", "Section" , "Subsection", "Page.Code", "Title","Short.Code")
cso_database <- cso_database[c("Theme", "Section" , "Subsection","Title",
"Page.Code", "Short.Code")]
devtools::use_data(cso_database , overwrite = TRUE )
roxygen2::roxygenize()
devtools::install_github("brendanjodowd/CSO")
library(CSO)
the_database <- cso_database
View(the_database)
source('~/R/CSO/R/building_database.R', echo=TRUE)
View(cso_links)
cso_links <- read.csv("~/R/CSO/cso_links.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i]=so_links$V1[i-1]
}
if(cso_links$V2[i]=""){
cso_links$V2[i]=cso_links$V2[i-1]
}
if(cso_links$V3[i]=""){
cso_links$V3[i]=cso_links$V3[i-1]
}
}
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
if(cso_links$V2[i]=""){
cso_links$V2[i] <- cso_links$V2[i-1]
}
if(cso_links$V3[i]=""){
cso_links$V3[i] <- cso_links$V3[i-1]
}
}
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
# if(cso_links$V2[i]=""){
#   cso_links$V2[i] <- cso_links$V2[i-1]
# }
# if(cso_links$V3[i]=""){
#   cso_links$V3[i] <- cso_links$V3[i-1]
# }
}
cso_links$V1[3]
cso_links$V1[1]
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
}
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
}
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]==""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
}
cso_links <- read.csv("~/R/CSO/cso_links.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]==""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
if(cso_links$V2[i]=""){
cso_links$V2[i] <- cso_links$V2[i-1]
}
if(cso_links$V3[i]=""){
cso_links$V3[i] <- cso_links$V3[i-1]
}
}
cso_links <- read.csv("~/R/CSO/cso_links.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]==""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
if(cso_links$V2[i]==""){
cso_links$V2[i] <- cso_links$V2[i-1]
}
if(cso_links$V3[i]==""){
cso_links$V3[i] <- cso_links$V3[i-1]
}
}
source('~/R/CSO/R/building_database.R', echo=TRUE)
source('~/R/CSO/R/building_database.R', echo=TRUE)
source('~/R/CSO/R/building_database.R', echo=TRUE)
devtools::install_github("brendanjodowd/CSO")
source('~/R/CSO/R/building_database.R', echo=TRUE)
devtools::install_github("brendanjodowd/CSO")
library(CSO)
mydata <- get_cso("AIA30")
View(mydata)
the_database <- cso_database
View(the_database)
table(the_database$Theme)
source('~/R/CSO/R/get_cso.R', echo=TRUE)
mydata <- get_cso("AIA30")
library(CSO)
library(CSO)
mydata <- get_cso("BBA01")
print(first.line.of.text)
print(first.line.of.text)
source('~/.active-rstudio-document', echo=TRUE)
roxygenize()
roxygenize
?roxygen
?roxygenize
library(roxygen2)
roxygenize()
detach("httr", unload=TRUE)
detach("rjstat", unload=TRUE)
detach("stringr", unload=TRUE)
detach(httr, unload=TRUE)
detach(package:httr, unload=TRUE)
detach(package:stringr, unload=TRUE)
detach(package:rjstat, unload=TRUE)
library(rjstat)
detach(package:rjstat, unload=TRUE)
devtools::install_github("brendanjodowd/CSO")
library(CSO)
mydata <- get_cso("BBA01")
devtools::install_github("brendanjodowd/CSO")
rm(statbank)
rm(get_cso)
devtools::install_github("brendanjodowd/CSO")
library(CSO)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
library(CSO)
mydata <- get_cso("BBA01")
mydata <- get_cso("muck")
detach(package:rjstat, unload=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
library(CSO)
mydata <- get_cso("muck")
devtools::install_github("brendanjodowd/CSO", force=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
library(CSO)
?CSO
??CSO
packageDescription("CSO")
?get_cso
?statbank
?detach
?statbank
help(get_cso)
help("summarise")
help("get_cso")
library(CSO)
help(get_cso)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
library(CSO)
mydata <- get_cso("muck")
mydata <- get_cso("muck")
detach(package:rjstat, unload=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
roxygenize()
source('~/.active-rstudio-document', echo=TRUE)
library(rvest)
library(purrr)
library(tidyr)
library(dplyr)
library(stringr)
source('~/.active-rstudio-document', echo=TRUE)
View(statbank)
devtools::install_github("brendanjodowd/CSO", force=TRUE)
library(CSO)
help("get_cso")
packageDescription(CSO)
packageDescription("CSO")
devtools::install_github("brendanjodowd/CSO", force=TRUE)
library(CSO)
packageDescription("CSO")
?get_cso
the_database <- statbank
View(the_database)
packageDescription("CSO")
library(installr)
install.packages("installer")
install.packages("installr")
remove.packages("rjstat")
library(rjstat)
