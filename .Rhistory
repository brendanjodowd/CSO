cso_links$Short.Code[4]
cso_database$Code[4]
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database){
print(paste(cso_links$Short.Code , " " , cso_database$Code))
}
}
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database){
print(paste(cso_links$Short.Code , " " , cso_database$Code))
}
}
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database){
print(paste(cso_links$Short.Code , " " , cso_database$Code))
}
}
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database){
print(paste(cso_links$Short.Code[i] , " " , cso_database$Code[j]))
}
}
View(cso_links)
for(i in 1:nrow(cso_links)){
print(i)
}
for(i in 1:nrow(cso_links)){
print(cso_links[i])
}
for(i in 1:nrow(cso_links)){
print(cso_links$Short.Code[i])
}
for(i in 1:nrow(cso_links)){
print(cso_links$Short.Code[i])
for(j in 1:nrow(cso_database)){
print(cso_database$Code[j])
}
}
for(i in 1:nrow(cso_links)){
print(cso_links$Short.Code[i])
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_database$Code[j])
}
}
}
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
}
}
}
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
cso_database$Short.Code <- cso_links$Short.Code[i]
}
}
}
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
cso_database$Short.Code[i] <- cso_links$Short.Code[i]
}
}
}
library(rvest)
library(purrr)
library(tidyr)
library(dplyr)
library(stringr)
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles
}
#cso_links is the file from the CSV. The short codes here are correct!
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Code <- str_split_fixed(cso_database$Item, " -" , 2)[,1]
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
cso_database$Short.Code[i] <- cso_links$Short.Code[i]
}
}
}
library(rvest)
library(purrr)
library(tidyr)
library(dplyr)
library(stringr)
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles
}
#cso_links is the file from the CSV. The short codes here are correct!
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Code <- str_split_fixed(cso_database$Item, " -" , 2)[,1]
cso_database$Short.Code <- ""
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
cso_database$Short.Code[i] <- cso_links$Short.Code[i]
}
}
}
cso_database$Short.Code <- ""
for(i in 1:nrow(cso_links)){
for(j in 1:nrow(cso_database)){
if(str_detect(cso_database$Code[j] , cso_links$Short.Code[i])){
print(cso_links$Short.Code[i])
print(cso_database$Code[j])
print(" ")
cso_database$Short.Code[j] <- cso_links$Short.Code[i]
}
}
}
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
short.code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles <- paste(short.code , " - " , titles)
titles
}
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database <- map(cso_links_vec , extract_links)
sample_link <- "https://www.cso.ie/webserviceclient/datasets.aspx?sp=DB_EY&SPtext=Summary%20Results%20Part%201"
sample_page <- extract_links(sample_link)
sample_page <- unnest(tibble(extract_links(sample_link)))
View(sample_page)
sample_page <- tibble(extract_links(sample_link))
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
# short.code <- link_address %>%
#   str_extract(".*(?=&SPtext)") %>%
#   str_extract("(?<=DB_).*")
# titles <- paste(short.code , " - " , titles)
titles
}
sample_page <- tibble(extract_links(sample_link))
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database <- map(cso_links_vec , extract_links)
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
View(cso_database)
sample_page <- unnest(tibble(extract_links(sample_link)))
sample_page <- tibble(extract_links(sample_link))
sample_page <- extract_links(sample_link)
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("font")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
# short.code <- link_address %>%
#   str_extract(".*(?=&SPtext)") %>%
#   str_extract("(?<=DB_).*")
# titles <- paste(short.code , " - " , titles)
titles
}
sample_page <- extract_links(sample_link)
extract_text <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_text()
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles
}
sample_page <- extract_text(sample_link)
extract_text <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("href") %>% html_text()
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles
}
sample_page <- extract_text(sample_link)
rm(extract_text())
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Short.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Short.Code , titles$Item , sep=" * ")
titles
}
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Short.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
#cso_database <- map(cso_links_vec , extract_links)
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
rm(sample_page)
cso_database$Page.Code <- str_split_fixed(cso_database$Item, " *" , 2)[,1]
cso_database$Code <- str_split_fixed(cso_database$Item, " -" , 2)[,1]
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Page.Code <- str_extract(cso_database$Item, "^.*_ " )
cso_database$Page.Code <- cso_database$Item %>% str_extract(" ")
cso_database$Page.Code <- cso_database$Item %>% str_extract("^.*_ " ) %>% str_replace(" _","")
cso_database$Short.Code <- cso_database$Item %>% str_extract(" _.*- " )
cso_database$Page.Code <- cso_database$Item %>% str_extract("^.{1,10}_ " ) %>% str_replace(" _","")
cso_database$Page.Code <- cso_database$Item %>% str_extract("^.*_ " ) %>% str_replace(" _","")
cso_database$Short.Code <- cso_database$Item %>% str_extract(" _.{1,10}- " )
cso_database$Short.Code <- cso_database$Item %>% str_extract(" _.{1,10}- " ) %>%
str_replace_all("[:punct:]","")
cso_database$New.Item <- str_replace(cso_database$Page.Code , "")
cso_database$New.Item <- str_replace(paste(cso_database$Page.Code) , "")
cso_database$New.Item <- str_replace(paste(cso_database$Page.Code) , "")
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titles
}
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titels$PC <- Page.Code
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titles$PC <- Page.Code
titles
}
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles$Item <- paste(Page.Code , titles$Item , sep=" _ ")
titles$PC <- Page.Code
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles$Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " )
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]") %>% str_replace("[:blank:]")
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
cso_database <- full_join(cso_links , cso_database , by="Short.Code")
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
combined_dataset <- full_join(cso_links , cso_database , by="Short.Code")
library(rvest)
library(purrr)
library(tidyr)
library(dplyr)
library(stringr)
#cso_links is the file from the CSV. The short codes here are correct!
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles$Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
combined_dataset <- full_join(cso_links , cso_database , by="Page.Code")
View(combined_dataset)
cso_database <- full_join(cso_links , cso_database , by="Page.Code")
cso_database_1 <- select(cso_database , -V4)
View(cso_database_1)
rm(cso_database_1)
names(cso_database) <- c("Theme", "Section" , "Subsection", "Page.Code", "Title","Short.Code")
library(rvest)
library(purrr)
library(tidyr)
library(dplyr)
library(stringr)
#cso_links is the file from the CSV. The short codes here are correct!
cso_links <- read.csv("~/R/CSO/small_list.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
extract_links <-  function(link_address){
webpage <- read_html(paste(link_address)) %>% html_nodes(".row") %>% html_nodes("a")
titles <- tibble(webpage %>% html_text() )
names(titles) <- "Item"
titles <- titles %>% filter(Item!="Table" & Item != "JSON")
titles$Page.Code <- link_address %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
titles
}
#cso_database is from the web-scraping.
cso_database <- unnest(tibble(map(cso_links_vec , extract_links)))
cso_database$Short.Code <- cso_database$Item %>% str_extract("^.{1,8}- " ) %>%
str_replace("[:punct:]","") %>% str_replace("[:blank:]","")
cso_database <- full_join(cso_links , cso_database , by="Page.Code")
cso_database <- select(cso_database , -V4)
names(cso_database) <- c("Theme", "Section" , "Subsection", "Page.Code", "Title","Short.Code")
cso_database <- cso_database[c("Theme", "Section" , "Subsection","Title",
"Page.Code", "Short.Code")]
devtools::use_data(cso_database , overwrite = TRUE )
roxygen2::roxygenize()
devtools::install_github("brendanjodowd/CSO")
library(CSO)
the_database <- cso_database
View(the_database)
source('~/R/CSO/R/building_database.R', echo=TRUE)
View(cso_links)
cso_links <- read.csv("~/R/CSO/cso_links.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i]=so_links$V1[i-1]
}
if(cso_links$V2[i]=""){
cso_links$V2[i]=cso_links$V2[i-1]
}
if(cso_links$V3[i]=""){
cso_links$V3[i]=cso_links$V3[i-1]
}
}
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
if(cso_links$V2[i]=""){
cso_links$V2[i] <- cso_links$V2[i-1]
}
if(cso_links$V3[i]=""){
cso_links$V3[i] <- cso_links$V3[i-1]
}
}
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
# if(cso_links$V2[i]=""){
#   cso_links$V2[i] <- cso_links$V2[i-1]
# }
# if(cso_links$V3[i]=""){
#   cso_links$V3[i] <- cso_links$V3[i-1]
# }
}
cso_links$V1[3]
cso_links$V1[1]
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
}
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]=""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
}
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]==""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
}
cso_links <- read.csv("~/R/CSO/cso_links.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]==""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
if(cso_links$V2[i]=""){
cso_links$V2[i] <- cso_links$V2[i-1]
}
if(cso_links$V3[i]=""){
cso_links$V3[i] <- cso_links$V3[i-1]
}
}
cso_links <- read.csv("~/R/CSO/cso_links.csv", header=FALSE)
cso_links_vec <- pull(cso_links[4], V4)
cso_links$Page.Code <- cso_links$V4 %>%
str_extract(".*(?=&SPtext)") %>%
str_extract("(?<=DB_).*")
for(i in 2:nrow(cso_links)){
if(cso_links$V1[i]==""){
cso_links$V1[i] <- cso_links$V1[i-1]
}
if(cso_links$V2[i]==""){
cso_links$V2[i] <- cso_links$V2[i-1]
}
if(cso_links$V3[i]==""){
cso_links$V3[i] <- cso_links$V3[i-1]
}
}
source('~/R/CSO/R/building_database.R', echo=TRUE)
source('~/R/CSO/R/building_database.R', echo=TRUE)
source('~/R/CSO/R/building_database.R', echo=TRUE)
devtools::install_github("brendanjodowd/CSO")
source('~/R/CSO/R/building_database.R', echo=TRUE)
